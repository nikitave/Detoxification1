{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c5154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b740044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57809</td>\n",
       "      <td>Listen, call off the butchers, and I'll tell you.</td>\n",
       "      <td>call out your butchers and I'll tell you.</td>\n",
       "      <td>0.761781</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.968063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132693</td>\n",
       "      <td>Who the fuck has been going through my stuff?!</td>\n",
       "      <td>who the hell was going through my stuff?</td>\n",
       "      <td>0.898699</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.997644</td>\n",
       "      <td>0.452115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254505</td>\n",
       "      <td>She still might die . . .?</td>\n",
       "      <td>he can still die.</td>\n",
       "      <td>0.635970</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.279049</td>\n",
       "      <td>0.989168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>451186</td>\n",
       "      <td>Yeah, that's the fucker's name.</td>\n",
       "      <td>that's what his name was.</td>\n",
       "      <td>0.652426</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191213</td>\n",
       "      <td>I would take you on my shoulders, like, I'd st...</td>\n",
       "      <td>I'd take you on your shoulders... I'd tie you ...</td>\n",
       "      <td>0.790915</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.961127</td>\n",
       "      <td>0.028628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          reference  \\\n",
       "0       57809  Listen, call off the butchers, and I'll tell you.   \n",
       "1      132693     Who the fuck has been going through my stuff?!   \n",
       "2      254505                         She still might die . . .?   \n",
       "3      451186                    Yeah, that's the fucker's name.   \n",
       "4      191213  I would take you on my shoulders, like, I'd st...   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0          call out your butchers and I'll tell you.    0.761781     0.160000   \n",
       "1           who the hell was going through my stuff?    0.898699     0.127660   \n",
       "2                                  he can still die.    0.635970     0.333333   \n",
       "3                          that's what his name was.    0.652426     0.187500   \n",
       "4  I'd take you on your shoulders... I'd tie you ...    0.790915     0.357143   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.005592  0.968063  \n",
       "1  0.997644  0.452115  \n",
       "2  0.279049  0.989168  \n",
       "3  0.999579  0.000055  \n",
       "4  0.961127  0.028628  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/test_dataset.tsv\", delimiter=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936db883",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5c51def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "model_name=\"t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193fe96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bfffd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f37d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 903/903 [07:21<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "output = []\n",
    "for i in trange(0, len(data.reference), 128):\n",
    "    tokens = tokenizer(\n",
    "        list(data.reference[i:i + 128]),\n",
    "        padding=\"max_length\",\n",
    "        max_length=50,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    out = model.generate(\n",
    "        input_ids = tokens[\"input_ids\"],\n",
    "        attention_mask = tokens[\"attention_mask\"],\n",
    "        max_length= 50,\n",
    "        num_return_sequences = 1\n",
    "    )\n",
    "    output += [tokenizer.decode(\n",
    "        gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    ) for gen_id in out]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7cee1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ec0934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76a01ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b346d5cfdef54f16805267a02b702003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fa620621160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b669b9273748edaccc3ac0b7f964b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings1 = []\n",
    "embeddings2 = []\n",
    "\n",
    "embeddings1 = model.encode(list(data.reference), show_progress_bar=True, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(output, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69fe672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115555/115555 [00:11<00:00, 10144.84it/s]\n"
     ]
    }
   ],
   "source": [
    "cosine_scores = []\n",
    "for i in trange(len(embeddings1)):\n",
    "    cosine_scores += util.cos_sim(embeddings1[i], embeddings2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb3c046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8497145771980286\n"
     ]
    }
   ],
   "source": [
    "average_similiraty_score = sum(cosine_scores) / len(embeddings1)\n",
    "print(float(average_similiraty_score.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b960f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a12600c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c8a271459849c080fe3d3f73e9f69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c208c2b08f1485aa6e896cc1ac364b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/47.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = 'cointegrated/rubert-tiny-toxicity'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1019a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity(text, aggregate=True):\n",
    "    \"\"\" Calculate toxicity of a text (if aggregate=True) or a vector of toxicity aspects (if aggregate=False)\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(model.device)\n",
    "        proba = torch.sigmoid(model(**inputs).logits).cpu().numpy()\n",
    "    if isinstance(text, str):\n",
    "        proba = proba[0]\n",
    "    if aggregate:\n",
    "        return 1 - proba.T[0] * (1 - proba.T[-1])\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e537d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115555/115555 [02:57<00:00, 649.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58475.971778956104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sum_toxicity = 0\n",
    "for i in trange (len(data)):\n",
    "    sum_toxicity += text2toxicity(data.reference[i], True)\n",
    "print(sum_toxicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f33b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060444963779681\n"
     ]
    }
   ],
   "source": [
    "result_toxicity_average_before = sum_toxicity / len(data)\n",
    "print(result_toxicity_average_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d50fe779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115555/115555 [02:53<00:00, 665.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52378.66827116993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sum_toxicity = 0\n",
    "for i in trange (len(data)):\n",
    "    sum_toxicity += text2toxicity(output[i], True)\n",
    "print(sum_toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cbd968db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45327911618856764\n"
     ]
    }
   ],
   "source": [
    "result_toxicity_average_before = sum_toxicity / len(output)\n",
    "print(result_toxicity_average_before)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
